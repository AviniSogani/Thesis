Forming the Dataset:


For each program:
	1. Generate mutants
	2. For each fitness function, search budget:
   		a. Generate 10 test suites for program
	3. Run each suite on all mutants
	4. For each mutant, collect number of failures, errors, total number of tests


Dataset:
Program, Search Budget, Fitness Function, Suite Number, Mutant ID, Failures, Errors, Total Tests


Yields for each search budget + fitness function + mutant, the probability of mutant detection


P(MDetection) = (number of suites that detected that mutant / total number of test suites (10))


To choose combinations:


Divide set of mutants into 10 training + test sets. 
* Divide mutants into 10 bins
* Each training set contains 90% of mutants, each test set is remaining 10%


1. For each training set:
   1. For each search budget:
      1. Choose fitness function that detects the most mutants.
      2. Remove all mutants from training set detected by that function.
      3. From remainder, choose fitness function detecting most mutants from remainder, add to combination
      4. Remove all mutants detected by that function.
      5. Continue until finished or 4 criteria in the combination.


If multiple fitness functions tie (detect same number of mutants):
* For each mutant detected by the function, calculate the sum of the P(MDetection)
* The one with the highest sum is the winner


This will yield:
* For each program and search budget, 10 combinations of fitness functions


Once we have combinations:


1. For each program:
   1. For each search budget:
      1. Generate 10 test suites for each combination (this includes the combinations formed from the other search budget)
1. Run the tests on each mutant, collecting the same data set as in the original single fitness function experiment
2. For each combination:
   1. Assess number of mutants detected from each of the 10 test sets. This tells you how good each combination is at detecting “new” faults.






Presentation:
* 45 minutes
* Introduction
   * Testing
   * Testing is expensive, automated generation can help lower costs
   * Search-based generation is a form of automated generation
   * Talk about search-based generation
   * SB generation is guided by fitness functions
   * Fitness functions represent testing goals
   * Many goals are based on code coverage, such as branch coverage
      * What is branch coverage?
      * What is the fitness function for branch coverage? How does it differ from just measuring branch coverage?
* Problem
   * We don’t know what fitness function will be the best for detecting faults.
   * Likely to differ between systems
   * Group of functions may be better than one. How code is executed matters for fault detection. Two tests may execute the same code in different ways because they offer different input. One fitness function may generate a test that triggers a fault. Another might not. A combination of functions may cause code to be executed in a manner that yields more effective tests.
   * Even harder challenge - what group of fitness functions should we use?
* The Solution
   * An automated method to choose a combination
   * This can be automated through the use of mutants.
   * Mutants are synthetic faults generated by transforming code using mutation operators
   * Examples of mutation operators
   * Process:
      * Choose program
      * Generate mutants
      * Generate 10 test suites for each mutant for each fitness function
      * Choose combination using a greedy strategy
      * Go over greedy strategy
* Study
   * Research questions we want to address
   * Perform process for two search budgets to see if more time yields better results
   * Split into training and test sets to test stability of results
   * Evaluate using the test sets to see if this detects “new” faults
* Timeline
   * What is done
   * What you need to do
   * When this will happen
   * When you will be done
* Conclusion


Research Questions:
1. Will this mutation-based process yield effective combinations of fitness functions?
2. Are the combinations more effective than single fitness functions?
3. How stable are the combinations produced?
   1. (in other words, how many training sets produce the same combinations?)
1. What is the effect of increasing the search budget?
2. Across programs, do we see patterns in the combinations chosen? 
   1. (do most programs result in the same combinations, or different ones?)
